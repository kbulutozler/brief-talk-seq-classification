{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgAlxl03nm1X"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets evaluate tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.backend import clear_session\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "from google.colab import files\n",
        "import io\n",
        "import warnings"
      ],
      "metadata": {
        "id": "d6-vjjko99jq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ohvyZ1qMBJuX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKR7AblU9ky4",
        "outputId": "2631ae6b-0f8f-4e1b-df36-222935fcf470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "R4Tj3oo74fsK",
        "outputId": "1facac00-f83d-4f4f-9cf4-b93fdf772bd7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5b23d5d1-4182-4daa-9bb1-4354e3c51c27\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5b23d5d1-4182-4daa-9bb1-4354e3c51c27\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dev.csv to dev.csv\n",
            "Saving test.csv to test.csv\n",
            "Saving train.csv to train.csv\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ikx2Co5B4sa-"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(io.BytesIO(uploaded['train.csv']))\n",
        "dev_df = pd.read_csv(io.BytesIO(uploaded['dev.csv']))\n",
        "test_df = pd.read_csv(io.BytesIO(uploaded['test.csv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pvwaCllD_P1k"
      },
      "outputs": [],
      "source": [
        "def get_vectorized_data(reviews_train, reviews_test):\n",
        "    vectorizer = CountVectorizer()\n",
        "    vectorizer.fit(reviews_train)\n",
        "    x_train = vectorizer.transform(reviews_train)\n",
        "    x_test = vectorizer.transform(reviews_test)\n",
        "    return x_train, x_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_df = pd.concat([train_df, dev_df, test_df]).reset_index(drop=True)\n",
        "all_df = all_df.sample(frac=1).reset_index(drop=True)\n",
        "all_df = all_df[:20000]\n",
        "reviews = all_df['text'].values\n",
        "labels = all_df['label'].values\n",
        "\n",
        "\n",
        "reviews_train, reviews_test, y_train, y_test = train_test_split(\n",
        "    reviews, labels, test_size=0.15, random_state=1000)"
      ],
      "metadata": {
        "id": "ja2r9oJd_6iX"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression and Simple Neural Network**"
      ],
      "metadata": {
        "id": "eiysOcg-_7c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = get_vectorized_data(reviews_train, reviews_test)\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "print(\"Logistic Regression results: \")\n",
        "print(f\"accuracy: {acc}, precision: {prec}, recall: {rec}, f1 score: {f1}\")\n",
        "\n",
        "input_dim = x_train.shape[1]\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(x_train, y_train, epochs=3, verbose='auto',batch_size=100)\n",
        "clear_session()\n",
        "y_pred = model.predict(x_test, batch_size=1250)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "print(\"Simple Neural Network results: \")\n",
        "print(f\"accuracy: {acc}, precision: {prec}, recall: {rec}, f1 score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybg1BKSCADpu",
        "outputId": "6b224bec-1d98-4fa1-9407-0cd2b71ca9f8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression results: \n",
            "accuracy: 0.896, precision: 0.8978919631093544, recall: 0.8967105263157895, f1 score: 0.8973008558262016\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                748070    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 748,081\n",
            "Trainable params: 748,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "170/170 [==============================] - 2s 5ms/step - loss: 0.4369 - accuracy: 0.8311\n",
            "Epoch 2/3\n",
            "170/170 [==============================] - 1s 5ms/step - loss: 0.1877 - accuracy: 0.9492\n",
            "Epoch 3/3\n",
            "170/170 [==============================] - 1s 5ms/step - loss: 0.1014 - accuracy: 0.9779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f56351b04d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 8ms/step\n",
            "Simple Neural Network results: \n",
            "accuracy: 0.9076666666666666, precision: 0.9001931745009659, recall: 0.9197368421052632, f1 score: 0.909860071591279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Neural Networks with Embedding Layer**"
      ],
      "metadata": {
        "id": "Bi-2HIuNBW5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(reviews_train)\n",
        "x_train = tokenizer.texts_to_sequences(reviews_train)\n",
        "x_test = tokenizer.texts_to_sequences(reviews_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1 \n",
        "maxlen = 100\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "embedding_dim = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size, \n",
        "                           output_dim=embedding_dim, \n",
        "                           input_length=maxlen))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x_train, y_train, epochs=5, verbose='auto',batch_size=100, validation_split=0.0)\n",
        "clear_session()\n",
        "y_pred = model.predict(x_test, batch_size=1250)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "print(\"Simple Neural Networks with Embedding Layer results: \")\n",
        "print(f\"accuracy: {acc}, precision: {prec}, recall: {rec}, f1 score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyvAYRW-A5yo",
        "outputId": "107c7c28-9775-440f-bc22-81addd2ab10d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          10370432  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12800)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                128010    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,498,453\n",
            "Trainable params: 10,498,453\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "170/170 [==============================] - 2s 8ms/step - loss: 0.4924 - accuracy: 0.7400\n",
            "Epoch 2/5\n",
            "170/170 [==============================] - 1s 8ms/step - loss: 0.1558 - accuracy: 0.9473\n",
            "Epoch 3/5\n",
            "170/170 [==============================] - 2s 11ms/step - loss: 0.0319 - accuracy: 0.9953\n",
            "Epoch 4/5\n",
            "170/170 [==============================] - 2s 13ms/step - loss: 0.0076 - accuracy: 0.9996\n",
            "Epoch 5/5\n",
            "170/170 [==============================] - 2s 12ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Simple Neural Networks with Embedding Layer results: \n",
            "accuracy: 0.892, precision: 0.888816644993498, recall: 0.8993421052631579, f1 score: 0.8940483976455199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Neural Network with Simple Neural Network and Embedding Layer**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oSRExflpBtzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(reviews_train)\n",
        "x_train = tokenizer.texts_to_sequences(reviews_train)\n",
        "x_test = tokenizer.texts_to_sequences(reviews_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1 \n",
        "maxlen = 100\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "embedding_dim = 128\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size, \n",
        "                           output_dim=embedding_dim, \n",
        "                           input_length=maxlen))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.Dropout(0.05))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(x_train, y_train, epochs=6, verbose='auto',batch_size=100, validation_split=0.1)\n",
        "clear_session()\n",
        "y_pred = model.predict(x_test, batch_size=1250)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "print(\"Convolutional Neural Network with Simple Neural Network and Embedding Layer results: \")\n",
        "print(f\"accuracy: {acc}, precision: {prec}, recall: {rec}, f1 score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMS536KOBi7E",
        "outputId": "6b79c76f-9b9f-4878-8271-82d9827f2d61"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          10370432  \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 96, 128)           82048     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 96, 128)           0         \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,453,781\n",
            "Trainable params: 10,453,781\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/6\n",
            "153/153 [==============================] - 3s 17ms/step - loss: 0.5079 - accuracy: 0.7524 - val_loss: 0.3567 - val_accuracy: 0.8382\n",
            "Epoch 2/6\n",
            "153/153 [==============================] - 2s 12ms/step - loss: 0.2617 - accuracy: 0.8954 - val_loss: 0.3443 - val_accuracy: 0.8547\n",
            "Epoch 3/6\n",
            "153/153 [==============================] - 2s 12ms/step - loss: 0.1340 - accuracy: 0.9595 - val_loss: 0.3309 - val_accuracy: 0.8659\n",
            "Epoch 4/6\n",
            "153/153 [==============================] - 2s 12ms/step - loss: 0.0541 - accuracy: 0.9875 - val_loss: 0.3697 - val_accuracy: 0.8659\n",
            "Epoch 5/6\n",
            "153/153 [==============================] - 2s 12ms/step - loss: 0.0153 - accuracy: 0.9987 - val_loss: 0.4275 - val_accuracy: 0.8694\n",
            "Epoch 6/6\n",
            "153/153 [==============================] - 2s 11ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.4741 - val_accuracy: 0.8647\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "Convolutional Neural Network with Simple Neural Network and Embedding Layer results: \n",
            "accuracy: 0.8723333333333333, precision: 0.8742593811718236, recall: 0.8736842105263158, f1 score: 0.8739717012175058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM Network with Simple Neural Network and Embedding Layer**"
      ],
      "metadata": {
        "id": "tH8EK1KQCRaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(reviews_train)\n",
        "x_train = tokenizer.texts_to_sequences(reviews_train)\n",
        "x_test = tokenizer.texts_to_sequences(reviews_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1 \n",
        "maxlen = 100\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "embedding_dim = 128\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size, \n",
        "                           output_dim=embedding_dim, \n",
        "                           mask_zero=True))\n",
        "#model.add(layers.Bidirectional(layers.LSTM(128, kernel_regularizer='l2')))\n",
        "model.add(layers.LSTM(128, kernel_regularizer='l2', return_sequences=True))\n",
        "model.add(layers.Dropout(0.05))\n",
        "model.add(layers.LSTM(128, kernel_regularizer='l2'))\n",
        "model.add(layers.Dense(10, activation='relu', kernel_regularizer='l2'))\n",
        "model.add(layers.Dense(1))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(x_train, y_train, epochs=8, verbose='auto',batch_size=100, validation_split=0.1)\n",
        "clear_session()\n",
        "y_pred = model.predict(x_test, batch_size=1250)\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "print(\"LSTM Network with Simple Neural Network and Embedding Layer results: \")\n",
        "print(f\"accuracy: {acc}, precision: {prec}, recall: {rec}, f1 score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx_ocxalCCVb",
        "outputId": "620b3e84-c766-4890-c393-b768a3725332"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 128)         10370432  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 128)         131584    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 128)         0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,634,901\n",
            "Trainable params: 10,634,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/8\n",
            "153/153 [==============================] - 14s 43ms/step - loss: 2.2005 - accuracy: 0.6774 - val_loss: 1.1281 - val_accuracy: 0.7776\n",
            "Epoch 2/8\n",
            "153/153 [==============================] - 4s 29ms/step - loss: 0.8626 - accuracy: 0.7974 - val_loss: 0.6280 - val_accuracy: 0.8471\n",
            "Epoch 3/8\n",
            "153/153 [==============================] - 4s 28ms/step - loss: 0.5825 - accuracy: 0.8602 - val_loss: 0.5678 - val_accuracy: 0.8300\n",
            "Epoch 4/8\n",
            "153/153 [==============================] - 3s 23ms/step - loss: 0.4129 - accuracy: 0.8975 - val_loss: 0.5452 - val_accuracy: 0.8518\n",
            "Epoch 5/8\n",
            "153/153 [==============================] - 3s 23ms/step - loss: 0.3686 - accuracy: 0.8935 - val_loss: 0.4635 - val_accuracy: 0.8465\n",
            "Epoch 6/8\n",
            "153/153 [==============================] - 3s 23ms/step - loss: 0.3249 - accuracy: 0.9105 - val_loss: 0.7599 - val_accuracy: 0.8553\n",
            "Epoch 7/8\n",
            "153/153 [==============================] - 4s 23ms/step - loss: 0.3355 - accuracy: 0.9020 - val_loss: 0.6457 - val_accuracy: 0.8541\n",
            "Epoch 8/8\n",
            "153/153 [==============================] - 4s 27ms/step - loss: 0.2799 - accuracy: 0.9222 - val_loss: 0.5895 - val_accuracy: 0.8594\n",
            "3/3 [==============================] - 4s 46ms/step\n",
            "LSTM Network with Simple Neural Network and Embedding Layer results: \n",
            "accuracy: 0.8543333333333333, precision: 0.8641560188298588, recall: 0.8453947368421053, f1 score: 0.8546724309943464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-trained Language Model**\n",
        "\n"
      ],
      "metadata": {
        "id": "qKm4G-EbCdwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_dataset = {}\n",
        "train_dict = {\"text\": reviews_train, \"label\":y_train}\n",
        "test_dict = {\"text\": reviews_test, \"label\":y_test}\n",
        "all_dataset['train'] = Dataset.from_dict(train_dict)\n",
        "all_dataset['test'] = Dataset.from_dict(test_dict)\n",
        "all_dataset = DatasetDict(all_dataset)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_dataset = all_dataset.map(preprocess_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c75df5ca2d854859ae4653ec911b7bc4",
            "b4df78fa21bd4983b8674f486d9fdcd7",
            "fb234a6f95114a7c9e6c387673e3f26c",
            "e8a5ec69e5584eaba73571035e31b6d2",
            "61370b14aef24a928733fbf8337a4eb4",
            "4cae0bda73c342208052d06ee352d6ec",
            "5336e4f354d647c89a00f92048b10f9d",
            "ae51dc3dfaae447587e829a260f02fa8",
            "30dfe3da4da748448f1d2bed80a72661",
            "b363f2f3e4e2470ab3c13351652935b3",
            "ece5ead9ff3c4e2fbb8ddf0d1911c5ac",
            "fc5fbdd19f1448d0a376bcfb7a00e360",
            "996dbcf16b8e4387ac6162fdf5df316c",
            "74032b7fcccf442fb907b830433d3481",
            "552c076f4fcf48189c562a3403744294",
            "4ee9ec84be354257a5e4337192adfaaf",
            "59a205307dcb4f1cafcb09b70871ccc3",
            "ed5254415fd14347a3acd476bfa5a6e7",
            "e6c351d97fee498693ce5a91f69bbfe0",
            "ed007679f29c42aa8fe8cafc7f758b09",
            "eb85331a865b4e23b7e48c9a04591097",
            "9dbf865cad7948779815ce3034fb91d1"
          ]
        },
        "id": "2FCyyGn5FEp_",
        "outputId": "a45241aa-cb92-4f5b-9038-288b67982f01"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/043235d6088ecd3dd5fb5ca3592b6913fd516027/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/043235d6088ecd3dd5fb5ca3592b6913fd516027/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/043235d6088ecd3dd5fb5ca3592b6913fd516027/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/043235d6088ecd3dd5fb5ca3592b6913fd516027/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/043235d6088ecd3dd5fb5ca3592b6913fd516027/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/17 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c75df5ca2d854859ae4653ec911b7bc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc5fbdd19f1448d0a376bcfb7a00e360"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric = evaluate.load('accuracy')\n",
        "recall_metric = evaluate.load('recall')\n",
        "precision_metric = evaluate.load('precision')\n",
        "f1_metric = evaluate.load('f1')\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "R2wRg6N5FH0o"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./transformers-results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7wUGTTYLCcen",
        "outputId": "7c17a205-deed-41b1-d586-d261b34ab35e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/043235d6088ecd3dd5fb5ca3592b6913fd516027/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/043235d6088ecd3dd5fb5ca3592b6913fd516027/pytorch_model.bin\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 17000\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3189\n",
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3189' max='3189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3189/3189 34:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.386500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.285700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.212800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.188600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.114600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./transformers-results/checkpoint-500\n",
            "Configuration saved in ./transformers-results/checkpoint-500/config.json\n",
            "Model weights saved in ./transformers-results/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./transformers-results/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./transformers-results/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to ./transformers-results/checkpoint-1000\n",
            "Configuration saved in ./transformers-results/checkpoint-1000/config.json\n",
            "Model weights saved in ./transformers-results/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in ./transformers-results/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in ./transformers-results/checkpoint-1000/special_tokens_map.json\n",
            "Saving model checkpoint to ./transformers-results/checkpoint-1500\n",
            "Configuration saved in ./transformers-results/checkpoint-1500/config.json\n",
            "Model weights saved in ./transformers-results/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in ./transformers-results/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in ./transformers-results/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to ./transformers-results/checkpoint-2000\n",
            "Configuration saved in ./transformers-results/checkpoint-2000/config.json\n",
            "Model weights saved in ./transformers-results/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in ./transformers-results/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in ./transformers-results/checkpoint-2000/special_tokens_map.json\n",
            "Saving model checkpoint to ./transformers-results/checkpoint-2500\n",
            "Configuration saved in ./transformers-results/checkpoint-2500/config.json\n",
            "Model weights saved in ./transformers-results/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in ./transformers-results/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in ./transformers-results/checkpoint-2500/special_tokens_map.json\n",
            "Saving model checkpoint to ./transformers-results/checkpoint-3000\n",
            "Configuration saved in ./transformers-results/checkpoint-3000/config.json\n",
            "Model weights saved in ./transformers-results/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in ./transformers-results/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in ./transformers-results/checkpoint-3000/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3189, training_loss=0.21404326107854116, metrics={'train_runtime': 2100.3589, 'train_samples_per_second': 24.282, 'train_steps_per_second': 1.518, 'total_flos': 5951563590319200.0, 'train_loss': 0.21404326107854116, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "\n",
        "acc = accuracy_metric.compute(predictions=preds, references=predictions.label_ids)['accuracy']\n",
        "prec = precision_metric.compute(predictions=preds, references=predictions.label_ids)['precision']\n",
        "rec = recall_metric.compute(predictions=preds, references=predictions.label_ids)['recall']\n",
        "f1 = f1_metric.compute(predictions=preds, references=predictions.label_ids)['f1']\n",
        "\n",
        "print(\"Pre-trained Language Model results: \")\n",
        "print(f\"accuracy: {acc}, precision: {prec}, recall: {rec}, f1 score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "JvgS7wZQCwX_",
        "outputId": "0554adc8-9fa1-44ea-86e2-75b86a9f68d3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained Language Model results: \n",
            "accuracy: 0.9126666666666666, precision: 0.89, recall: 0.9322625698324022, f1 score: 0.9106412005457025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4UpxmwUpGTf9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c75df5ca2d854859ae4653ec911b7bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4df78fa21bd4983b8674f486d9fdcd7",
              "IPY_MODEL_fb234a6f95114a7c9e6c387673e3f26c",
              "IPY_MODEL_e8a5ec69e5584eaba73571035e31b6d2"
            ],
            "layout": "IPY_MODEL_61370b14aef24a928733fbf8337a4eb4"
          }
        },
        "b4df78fa21bd4983b8674f486d9fdcd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cae0bda73c342208052d06ee352d6ec",
            "placeholder": "",
            "style": "IPY_MODEL_5336e4f354d647c89a00f92048b10f9d",
            "value": " 94%"
          }
        },
        "fb234a6f95114a7c9e6c387673e3f26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae51dc3dfaae447587e829a260f02fa8",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30dfe3da4da748448f1d2bed80a72661",
            "value": 16
          }
        },
        "e8a5ec69e5584eaba73571035e31b6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b363f2f3e4e2470ab3c13351652935b3",
            "placeholder": "",
            "style": "IPY_MODEL_ece5ead9ff3c4e2fbb8ddf0d1911c5ac",
            "value": " 16/17 [00:09&lt;00:00,  1.72ba/s]"
          }
        },
        "61370b14aef24a928733fbf8337a4eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cae0bda73c342208052d06ee352d6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5336e4f354d647c89a00f92048b10f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae51dc3dfaae447587e829a260f02fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30dfe3da4da748448f1d2bed80a72661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b363f2f3e4e2470ab3c13351652935b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece5ead9ff3c4e2fbb8ddf0d1911c5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc5fbdd19f1448d0a376bcfb7a00e360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_996dbcf16b8e4387ac6162fdf5df316c",
              "IPY_MODEL_74032b7fcccf442fb907b830433d3481",
              "IPY_MODEL_552c076f4fcf48189c562a3403744294"
            ],
            "layout": "IPY_MODEL_4ee9ec84be354257a5e4337192adfaaf"
          }
        },
        "996dbcf16b8e4387ac6162fdf5df316c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59a205307dcb4f1cafcb09b70871ccc3",
            "placeholder": "",
            "style": "IPY_MODEL_ed5254415fd14347a3acd476bfa5a6e7",
            "value": " 67%"
          }
        },
        "74032b7fcccf442fb907b830433d3481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c351d97fee498693ce5a91f69bbfe0",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed007679f29c42aa8fe8cafc7f758b09",
            "value": 2
          }
        },
        "552c076f4fcf48189c562a3403744294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb85331a865b4e23b7e48c9a04591097",
            "placeholder": "",
            "style": "IPY_MODEL_9dbf865cad7948779815ce3034fb91d1",
            "value": " 2/3 [00:02&lt;00:00,  1.16ba/s]"
          }
        },
        "4ee9ec84be354257a5e4337192adfaaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59a205307dcb4f1cafcb09b70871ccc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed5254415fd14347a3acd476bfa5a6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6c351d97fee498693ce5a91f69bbfe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed007679f29c42aa8fe8cafc7f758b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb85331a865b4e23b7e48c9a04591097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dbf865cad7948779815ce3034fb91d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}